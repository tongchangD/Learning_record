# yolo 系列算法的总结文档

## yolo-V1

### 优劣

- 检测快，全局处理使背景错误少，泛化性能好；
- 网络粗糙；
- 不如R-CNN的检测效果好，定位召回不够好，全连接处理，固定尺寸；
- 小样本和群体性的检测效果差，定位不准
- 但是是一次性的检测 you only look once

### 知识点

- 输入：448*448的尺寸，最终经过两个全连接网络输出为7\*7\*(类别+4(定位)+1(confidence)+4(定位)+1(confidence)) 正负样本
- 定位的xywh，其中xy的值在0-1之间。
- yolov1没有anchor的概念。
- 损失函数：所有损失采用误差平方和计算，但是边界框损失时w与h采用开根号的误差平方和计算
  - 边界框损失  
  - 置信度损失 此处存在正负样本的问题
  - 类别损失 
  
   $Pr(Class_i|Object)×Pr(Object)×IOU\frac{truth}{pred}=Pr(Class_i)*IOU\frac{truth}{pred}$


## yolo-V2 (yolo9000)

### 在yolo-v1之后的一些尝试truck

- 添加BN层
  - 在卷积层后面添加BN层，提升2%Map，起正则化作用，删除dropout层；
- 更高尺寸的类别分类器
  - 以224 提升到448的分类器,提升4%Map；
- anchor的预测，
  - 提高了召回率，使得模型有了提升空间；
- Anchor的聚类
  - 采用K-means进行聚类，能够更好的训练和学习
- 目标检测框的预测
  - 对xy进行限制，使其只能预测本框周围的目标,提升5%Map； 
- 预测特征图
  - 特征融合，特征小目标融合，深度拼接， eg：26\*26的分辨率采用passthroughlayer层将其变为13\*13的最后通过通道相结合。
- 多尺度训练
  - 每10个epoch，更换一次图像输入尺度（输入尺寸应该为32的整数倍）。


### 效果

- 使用同样的数据以及增强方式，最终得到top1 72.9%的准确率和top5 91.2%的的准确率

### 小细节

- 卷积采用 卷积+BN+leakyRelu 而卷积是没有偏置的


## yolo-V5

### 部分改进

- focus 
  - 切片操作，使得数据通道增加，特征图大小降低。
  - focus的替换
    - 将focus模块替换成了6×6的普通卷积层（两者功能相同，但后者效率更高。）

- SPP替换成SPPF
  - 将输入层并行的通过不同大小的maxpool2D然后再融合输出，SPPF是将输入串行的依次通过三个kernel大小为5\*5的maxpool2D，最后进行concat拼接。计算量降低了。
  
- 输入端数据增强
  - Mosaic 数据增强
    - 四张图片随机裁剪拼接到一张图像上作为训练数据

  - 自适应锚框计算
    - 针对不同数据集，都会初始设定长宽的锚框，在网络训练中对预测输出框和真实框进行对比，计算两者差距，方向更新，迭代网络参数。
  - 自适应图片缩放
    - 在常用的目标检测算法中，将不同图片的尺寸缩放到一标准尺寸再进入检测网络，自适应添加较少的黑边。
  - 纺锤变换、缩放、平移、旋转、错切、随机旋转角度、随机水平翻转等
  - Mixup：将随机的两张样本按比例混合，分类的结果按比例分配；
  - Cutout：随机将样本的部分区域裁剪掉，并填充0像素值，分类的结果不变；
  - cutMix：将部分cut掉但不填充0像素而是随机填充训练集中的其他数据的区域像素值，分类结果按照一定比例分配；
  - Albumentations 第三方包
    - 滤波、直方图均衡化以及改变图像质量等等。
  - HSV、亮度、明暗、色度、饱和度等
  
- 训练测量
  - 多尺度随机训练
  - 自动anchor
  - Warmup 学习率更新，cosing的搁置
  - EMA学习加上了动量，使得更加平滑
  - 混合精度训练，减少对GPU显存的占用
  - 可调整的超参

- 输出端
  - bounding box 损失函数
    - IOU_Loss、GIOU_Loss、DIOU_Loss、CIOU_Loss，v5中使用的 CIOU_Loss 
  - nms非极大值抑制


- 损失计算
  - 分类损失
    - 采用BCEloss（二值交叉熵损失）,注意只计算正样本的分类损失。
  - obj损失
    - 采用BCEloss,这里的损失采用网络预测目标边界框与真实边界框的CIOU，计算的是所有样本的Obj损失。
  - 定位损失
    - 采用的CIOUloss，只计算正样本的定位损失。

  $LOSS = λ_1L_{cls} + λ_2L_{obj} +λ31L_{loc}$
  对三个预测特征层采用三个不同的损失权重


- 消除grid敏感度问题等