---
tags: 无人设备, 概率机器人, 笔记
---

[toc]

# 概率机器人学

## 第二章

### 概率的基本概念

一元正态分布密度函数
$$
p(x) = \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}
$$
多元正态密度函数
$$
p(x) = det(2\pi\Sigma)^{-\frac{1}{2}}\exp \left\{ -\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)\right\}
$$
其中x表示多维矢量，$\mu$为均值矢量；$\Sigma$为一个半正定对称矩阵（协方差矩阵）;det表示行列式的值，当x为标量时，$\Sigma=\sigma^2$。

协方差矩阵的计算
$$
C= \begin{bmatrix}cov(x,x) &cov(x,y) & cov(x,z) \\ 
cov(y,x)& cov(y,y)&cov(y,z) \\
cov(z,x)& cov(z,y)&cov(z,z)
 \end {bmatrix}
$$
因此举例说明上式的泛化性。当x=(x1,x2)。其中$x1\to N(\mu_1,\sigma_1^2)$,$x2\to N(\mu_2,\sigma_2^2)$ ，

那么其协方差矩阵为
$$
\Sigma =\begin{bmatrix}\sigma_1^2  &\rho\sigma_1\sigma_2   \\ 
\rho\sigma_1\sigma_2& \sigma_2^2 
 \end {bmatrix}
$$
其中$\rho$表示相关性
$$
\Sigma^{-1} =\frac{1}{det\Sigma}\begin{bmatrix}\sigma_2^2  &-\rho\sigma_1\sigma_2   \\ 
-\rho\sigma_1\sigma_2& \sigma_1^2 
 \end {bmatrix}
$$

所以
$$
p(x1,x2 )=\frac{1}{\sqrt{(2\pi)^2(1-\rho^2)\sigma_1^2\sigma_2^2}}\exp \left\{ -\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)\right\}
$$



后验概率：

后验概率是指在得到“结果”的信息后重新修正的概率，是“执果寻因”问题中的"果"。[先验概率](https://baike.baidu.com/item/先验概率)与后验概率有不可分割的联系，后验概率的计算要以先验概率为基础 [2] 。

事情还没有发生，要求这件事情发生的可能性的大小，是先验概率。事情已经发生，要求这件事情发生的原因是由某个因素引起的可能性的大小，是后验概率。

先验概率不是根据有关自然状态的全部资料测定的，而只是利用现有的材料(主要是历史资料)计算的；后验概率使用了有关自然状态更加全面的资料，既有先验概率资料，也有补充资料；

先验概率的计算比较简单，没有使用[贝叶斯公式](https://baike.baidu.com/item/贝叶斯公式/9683982)；而后验概率的计算，要使用贝叶斯公式，而且在利用样本资料计算逻辑概率时，还要使用理论[概率分布](https://baike.baidu.com/item/概率分布)，需要更多的[数理统计](https://baike.baidu.com/item/数理统计/408183)知识。



**假设一个学校里有60%男生和40%女生。女生穿裤子的人数和穿裙子的人数相等，所有男生穿裤子。一个人在远处随机看到了一个穿裤子的学生。那么这个学生是女生的概率是多少？**

>设A为男生，因此P(A)=0.6，P(1-A)=0.4。设穿裤子为事件B则P(B)=0.8，P(1-B)=0.2.另外P(B|1-A)=0.5,P(1-B|1-A)=0.5,P(B|A)=1,P(1-B|A)=0。
求P(1-A|B)=P(B|1-A)P(1-A)/P(B)=0.5*0.4/0.8=0.25。



### 高斯滤波
$$
\hat{bel}(x_t)=\int p(x_t|x_{t-1},u_t)bel(x_{t-1})dx_{t-1} \\
bel(x_t)=\int p(x_t|z_t)\hat{bel}(x_t)dx_t
$$

$$
x_t表示当前真实状态 \\
u_t表示当前控制输出 \\
z_t表示当前测量量 \\
\hat x_t表示预测量 \\
\hat{bel}(x_t)是基于以前状态的后验，在综合时刻t的测量之前，预测了
时刻t的状态。
$$
**其核心思想为将控制与传感器测量进行数据统一, 以构成相互融合的关系。**
- 由于控制获取的状态数据符合高斯分布
- 测量获取的状态数据符合高斯分布

> 如果不符合高斯分布呢?

> 因为高斯分布只需要这两个参数描述即可。如果系统不服从线性和高斯的假设，后验概率密度函数显然不能用均值和协方差来简单描述，这就需要更加复杂的滤波器了，例如粒子滤波器。


**因此其高斯分布的*融合*也是高斯分布。**




### [融合高斯分布](https://blog.csdn.net/Ronnie_Hu/article/details/111378283)
$$
N(x,\mu_1,\sigma_1)=(2\pi*\sigma_1^2)^{-\frac{1}{2}}\exp(-\frac{(x-\mu_1)^2}{2\sigma_1^{2}})
$$
$$
N(x,\mu_2,\sigma_2)=(2\pi*\sigma_2^2)^{-\frac{1}{2}}\exp(-\frac{(x-\mu_2)^2}{2\sigma_2^{2}})
$$
$$
N(x,\mu_1,\sigma_1)*N(x,\mu_2,\sigma_2) \\
=(2\pi*\sigma_1^2)^{-\frac{1}{2}}\exp(-\frac{(x-\mu_1)^2}{2\sigma_1^{2}})*(2\pi*\Sigma_2^2)^{-\frac{1}{2}}\exp(-\frac{(x-\mu_2)^2}{2\sigma_2^{2}}) \\
=\frac{1}{\sqrt{2\pi*\sigma_1*\sigma_2}}\exp({-\frac{(x-\mu_1)^2}{2\sigma_1^{2}}-\frac{(x-\mu_2)^2}{2\sigma_2^{2}}}) \\
$$
令
$$
t={-\frac{(x-\mu_1)^2}{2\sigma_1^{2}}-\frac{(x-\mu_2)^2}{2\sigma_2^{2}}} \\
=-\frac{\sigma_1^2(x-\mu_1)^2+\sigma_2^2(x-\mu_2)^2}{2\sigma_1^2\sigma_2^2} \\
= -\frac{(x-\frac{\sigma_2^2\mu_1+\sigma_1^2\mu_2}{\sigma_1^2+\sigma_2^2})^2}{\frac{2\sigma_1^2\sigma_2^2}{\sigma_1^2+\sigma_2^2}}+\frac{(\mu_1-\mu_2)^2}{2(\sigma_1^2+\sigma_2^2)}
$$
令：
$$
\mu^{'}=\frac{\sigma_2^2\mu_1+\sigma_1^2\mu_2}{\sigma_1^2+\sigma_2^2} \\
\sigma^{'}=\sqrt{\frac{2\sigma_1^2\sigma_2^2}{\sigma_1^2+\sigma_2^2}} \\
S=\frac{1}{\sqrt{2\pi*\sigma_1*\sigma_2}}\exp{\frac{(\mu_1-\mu_2)^2}{2(\sigma_1^2+\sigma_2^2)}} \\
$$


因此：$N(x,\mu_1,\sigma_1)*N(x,\mu_2,\sigma_2)\backsim N(x,\frac{\sigma_2^2\mu_1+\sigma_1^2\mu_2}{\sigma_1^2+\sigma_2^2},\sqrt{\frac{2\sigma_1^2\sigma_2^2}{\sigma_1^2+\sigma_2^2}})$

### 马尔科夫链
其通俗的理解为后面状态只依靠前面状态确定，而不依靠其他。
定义：考虑一个随机变量序列$X=\{X_0,X_1,...,X_t,...\}$，这里$X_t$表示时刻t的随机变量，$t=0,1,2,...$。每个随机变量$X_t(t=0,1,2,...)$的取值集合相同，称为状态空间，表示为S，随机变量可以是连续的，也可以是离散的。以上随机变量的序列构成随机过程。
假设在时刻0的随机变量$X_0$遵循概率分布$P（X_0）=p_{i0}$,称为初始状态分布。在某个时刻$t \geq 1$的随机变量$X_t$与前一时刻的随机变量$X_{t-1}$之间有条件分布$P(X_t|X_{t-1})$,如果$X_t$只依赖于$X_{t-1}$，而不依赖于过去的随机变量$\{X_0,X_1,...,X_t-2{}\}$，这一性质称为马尔科夫性，即

$$
\begin{equation}
P(X_t|X_0,X_1,X_2,...,X_{t-1})=P(X_{t}|X_{t-1}), \text{t=1,2,... } \\
P(X_{t-1}|X_0,X_1,X_2,...,X_{t-2})=P(X_{t-1}|X_{t-2}),\text{t=1,2,...}
\end{equation}
$$

具有马尔科夫性的随机序列$X=\{X_0,X_1,...,X_t,...\}$称为马尔科夫链。或者马尔科夫过程。条件概率分布$P(X_{t}|X_{t-1})$称为马尔科夫链的转移概率分布。转移概率分布决定了马尔科夫链的特性。^[统计学习方法]

### 平稳分布
定义：设马尔科夫链$X=\{X_0,X_1,...,X_t,...\}$,其状态空间为S，转移矩阵为$P=(p_{ij})$,如果存在状态空间S上的一个分布
$$
\pi=\begin{bmatrix}\pi_1 \\ \pi_2 \\\pi_3 \\  .\\ . \\.\end{bmatrix}
$$
使得$\pi=P\pi$,则称$\pi$为马尔科夫链$X=\{X_0,X_1,...,X_t,...\}$的平稳分布。

引理：给定一个马尔科夫链$X=\{X_0,X_1,...,X_t,...\}$，状态空间为S，状态转移概率矩阵为$P=(p_{ij})$，则分布$\pi=(\pi_1,\pi_2,...)^T$为平稳分布的充分必要条件是$\pi=(\pi_1,\pi_2,...)^T$是下列方程组的解：
$$
\pi_i =  P(s_i)=\sum_1^np_{ij}P(s_j) ,\qquad i=1,2,3,... \\
P(s_j) \geq 0, \qquad i=1,2,3,... \\
\sum_iP(s_i)=1
$$
> 
> 如果状态空间$S(s_1,...,s_n)$包含了马尔科夫链$(x_1...x_t...)$的所有状态, 那么一定存在$\pi$,且$\pi = (p(s_1),p(s_2)...,p(s_n))^T$
### 蒙特卡洛算法

蒙特卡洛采样中含有序列蒙特卡洛(SMC)与马尔可夫链蒙特卡洛(MCMC)方法。

#### 1.蒙特卡洛的概念

蒙特卡洛原来是一个赌场的名称，用它作为名字大概是因为蒙特卡洛方法是一种随机模拟的方法，这很像赌博场里面的扔骰子的过程。最早的蒙特卡洛方法都是为了求解一些不太好求解的求和或者积分问题

例如下图是一个经典的用蒙特卡洛求圆周率的问题，用计算机在一个正方形之中随机的生成点，计数有多少点落在1/4圆之中，这些点的数目除以总的点数目即圆的面积，根据圆面积公式即可求得圆周率

蒙特卡洛算法的另一个应用是求积分，某些函数的积分不好求，我们可以按照下面的方法将这个函数进行分解，之后转化为求期望与求均值的问题。（通俗一点就是通过将一个函数分解为一个函数乘一个概率密度函数的形式）实现如下：
$$
\int_a^b h(x)dx = \int_a^bf(x)p(x)dx=E_{p(x)}[f(x)]
$$
上式通过转换将一个函数的定积分过程转换为求一个函数的在服从p(x)分布情况下的有限区间的期望问题。

从分布 $p(x)$采样大量样本点 $x_1,x_2,...,x_n$，这些样本符合分布 $p(x)$。
$$
E_{p(x)}[f(x)]=\frac{1}{n}\sum_{i=0}^n f(x_i)
$$

#### 2.蒙特卡洛采样方法

对某一种概率分布p(x)进行蒙特卡洛采样的方法主要分为直接采样、接受-拒绝采样与重要性采样三种，下面分别予以介绍。

##### 2.1 直接采样

直接采样的方法是根据概率分布进行采样。对一个已知概率密度函数与累积概率密度函数的概率分布，我们可以直接从累积分布函数（cdf）进行采样

如下图所示是高斯分布的累积概率分布函数，可以看出函数的值域是(0, 1)，我们可以从U(0, 1)均匀分布中进行采样，再根据累积分布函数的反函数计算对应的x，这样就获得了符合高斯分布的N个粒子。



使用累积分布函数进行采样看似简单，但是*由于很多分布我们并不能写出概率密度函数与累积分布函数*，所以这种方法的*适用范围较窄*



##### 2.2 接受-拒绝采样

对于累积分布函数未知的分布，我们可以采用接受-拒绝采样。如下图所示，$p(z)$是我们希望采样的分布，q(z)是我们提议的分布(proposal distribution)，令$kq(z)>p(z)$，我们首先在$kq(z)$中按照直接采样的方法采样粒子，接下来判断这个粒子落在途中什么区域，对于落在灰色区域的粒子予以拒绝，落在红线下的粒子接受，最终得到符合$p(z)$的N个粒子

##### 2.3 重要性采样

接受拒绝采样完美的解决了累积分布函数不可求时的采样问题。但是接受拒绝采样非常依赖于提议分布(proposal distribution)的选择，如果提议分布选择的不好，可能采样时间很长却获得很少满足分布的粒子。而重要性采样就解决了这一问题

直接采样与接受拒绝采样都是假设每个粒子的权重相等，而重要性采样则是给予每个粒子不同的权重，使用加权平均的方法来计算期望
$$
E_{p(x)}[f(x)]=\int_a^bf(x)\frac{p(x)}{q(x)}q(x)dx=E_{q(x)}[f(x)\frac{p(x)}{q(x)}]
$$
我们从提议分布$q(x)$中采样大量粒子$x_1,x_2,...,x_n$ ，每个粒子的权重是 $\frac{p(x)}{q(x)}$ ，通过加权平均的方式可以计算出期望
$$
E_{q(x)}[f(x)\frac{p(x)}{q(x)}] = \frac{1}{N}\sum_{i=0}^nf(x_i)\frac{p(x_i)}{q(x_i)}
$$

#### 3. 总结

蒙特卡洛方法是一种近似推断的方法，通过采样大量粒子的方法来求解期望、均值、面积、积分等问题，蒙特卡洛对某一种分布的采样方法有直接采样、接受拒绝采样与重要性采样三种，直接采样最简单，但是需要已知累积分布的形式。接受拒绝采样与重要性采样适用于原分布未知的情况，这两种方法都是给出一个提议分布，不同的是接受拒绝采样对不满足原分布的粒子予以拒绝，而重要性采样则是给予每个粒子不同的权重，大家可以根据不同的场景使用这三种方法中的一种进行采样。



## 第三章


### [卡尔曼滤波](https://blog.csdn.net/u010720661/article/details/63253509)

- 卡尔曼滤波数学模型建立
    $$
    x_t = A_tx_{t-1}+B_tu_t-\epsilon_t \\
    z_t = C_tx_t+\delta_t
    $$
    其中$A_t\to n\times n$，$x_t\to n\times 1$，$B_t\to n\times m$，$u_t\to m\times 1$，$\epsilon_t\to n\times 1$(高斯随机向量，也就是高斯噪声(为控制系统产生)，其均值为0，方差为$R_t$)，$C_t\to k\times n$，$z_t\to k\times 1$，$\delta_t\to k\times 1$(高斯随机向量，也就是高斯噪声(为测量系统产生)，其均值为0，方差为$Q_t$),$x_t, x_{t-1}为状态向量$,$u_t$为时刻t的控制向量,

    根据高斯滤波理论
    在其中存在初始置信度，定义为：
    $$
    bel(x_0)=p(x_0)=det(2\pi\Sigma_0)^{-\frac{1}{2}}\exp\{-\frac{1}{2}(x_0-\mu_0)^T\Sigma_0^{-1}(x_0-\mu_0)\}
    $$
    根据控制系统状态方程，计算状态转移概率：
    $$
    \hat{bel}(x_t)=p(x_t|u_t,x_{t-1})=det(2\pi R_{t})^{-\frac{1}{2}}\exp\{-\frac{1}{2}(x_t-A_tx_{t-1}-B_tu_t)^TR_t^{-1}(x_t-A_tx_{t-1}-B_tu_t)\}
    $$
    然后通过测量数据进行系统修正，其测量概率为：
    $$
    bel(x_t)=\eta p(z_t|x_t)\hat{bel}(x_t)= \eta det(2\pi Q_{t})^{-\frac{1}{2}}\exp\{-\frac{1}{2}(z_t-C_tx_{t})^TQ_t^{-1}(z_t-C_tx_{t})\}\hat{bel}(x_t)
    $$
    
    
- 卡尔曼滤波算法
    $kf(\mu_{t-1},\Sigma_{t-1},u_t,z_t):$

    $1 \qquad    \hat{\mu}_t=A_t\mu_{t-1}+B_tu_t$
    $2 \qquad    \hat{\Sigma}_t = A_t\Sigma_{t-1}A_t^T+R_t$
    $3 \qquad    K_t = \hat{\Sigma}_tC_t^T(C_t\hat{\Sigma}_tC_t^T+Q_t)^{-1}$
    $4 \qquad    \mu_t = \hat{\mu}_t + K_t(z_t-C_t\hat{\mu}_t)$
    $5 \qquad    \Sigma_t = (I-K_tC_t)\hat{\Sigma}_t$

    return  $\mu_t$ ,$\Sigma_t$ 
    - 上面算法描述了KF算法(Kalman filter algorithm)，KF的输入就是t-1时刻的置信度，其均值和方差分别用$\mu_{t-1}$,$\Sigma_{t-1}$表示。为了更新这些参数，KF需要控制向量$u_t$和测量向$z_t$。输出的是时刻t的置信度，均值$\mu_t$,方差$\Sigma_t$。
    - 在第2行和第3行，计算预测的置信度$\hat{\mu}_{t}$,$\hat{\Sigma}_{t}$,用于表示一步后的在综合测量向量$z_t$之前的置信度$\hat{bel}(x_t)$。这个置信度通过综合控制$u_t$获得。均值利用$x_t = A_tx_{t-1}+B_tu_t$的状态转移函数进行计算，状态向量$x_{t-1}$用均值向量$\mu_{t-1}$代替。方差是通过线性矩阵$A_t$考虑了当前状态依赖前一状态的事实进行计算的。因为方差是一个二次型的，所以该矩阵两次相乘得到方差。
    - 通过综合向量$z_t$,第4行到第6行将置信度$\hat{bel}(x_t)$顺序地转换成期望的置信度 bel(x,) 。第4行计算的变量矩阵$K_t$, 叫作卡尔曼增益(Kalman gain)矩阵。它明确了测量综合到新的状态估计的程度.第5行通过根据卡尔曼增益矩阵$K_t$, 、真实测量向量$z_t$的偏差及根据式$z_t = C_tx_t$测量概率预测的测量量进行调节来处理均值。这里的关键概念是更新(innovation),是指在真实测量向量$u_t$和第5行的期望测量量$C_t\hat{\mu}_t$之间的不同。最后，后验置信度的方差用第6行计算，调整由测量引起的信息增益。
    

### 扩展卡尔曼滤波

- 扩展卡尔曼滤波数学模型建立
    通过将**非线性控制系统**状态方程转换为**线性**，方法为获取方程**一阶泰勒展开**结果
    $$
    x_t = g(x_t,u_t)-\epsilon_t \\
    z_t = h(x_t)+\delta_t
    $$
    函数g取代了式卡尔曼滤波中的矩阵$A_t,B_t$,h取代了$C_t$,其中$R_t,Q_t$含义不变。
    $$
    g^{'}(u_t,x_{t-1})=\frac{\partial g(u_t,x_{t-1})}{\partial x_{t-1}}  :\to G_t \\
    g(u_t,x_{t-1})\approx g(u_t,\mu_{t-1})+g^{'}(u_t,\mu_{t-1})(x_{t-1}-\mu_{t-1}) \\
    = g(u_t,\mu_{t-1})+G_t(x_{t-1}-\mu_{t-1})
    $$
    状态转移概率:
    $$
    p(x_t|u_t,x_{t-1})= det(2\pi R_t)^{-\frac{1}{2}}\exp\{-\frac{1}{2}\left[x_t- g(u_t,\mu_{t-1})-G_t(x_{t-1}-\mu_{t-1})\right]^TR_t^{-1}\left[x_t- g(u_t,\mu_{t-1})-G_t(x_{t-1}-\mu_{t-1})\right]\}
    $$
    
    $$
    h^{'}(x_{t})=\frac{\partial h(x_{t})}{\partial x_{t}}  :\to H_t \\
    h(x_{t})\approx h(\hat \mu_{t})+h^{'}(\hat \mu_{t})(x_{t}-\hat \mu_{t}) \\
    = h(\hat \mu_{t})+H_t(x_{t}-\hat \mu_{t})
    $$
    其测量概率为：
    $$
    p(z_t|x_{t})= det(2\pi Q_t)^{-\frac{1}{2}}\exp\{-\frac{1}{2}\left[z_t- h(\hat \mu_{t})-H_t(x_{t}-\hat \mu_{t})\right]^TQ_t^{-1}\left[z_t- h(\hat \mu_{t})-H_t(x_{t}-\hat \mu_{t})\right]\}
    $$
    其中$G_t$表示函数g在均值处的$g^{'}(u_t,\mu_{t-1})$,其计算为求雅克比矩阵，其中$H_t$表示函数h在预测状态值均值处的$h^{'}(\hat{\mu}_{t})$，其计算为求雅克比矩阵
- 扩展卡尔曼滤波算法
    ekf($\mu_{t-1}$,$\Sigma_{t-1}$,$u_t$,$z_t$):

    $1 \qquad   \hat{\mu}_t=g(\mu_{t-1},u_t)$
    $2 \qquad   \hat{\Sigma}_t = G_t\Sigma_{t-1}G_t^T+R_t$
    $3 \qquad   K_t = \hat{\Sigma}_tH_t^T(H_t\hat{\Sigma}_tH_t^T+Q_t)^{-1}$
    $4 \qquad   \mu_t = \hat{\mu}_t + K_t(z_t-h(\hat{\mu}_t))$
    $5 \qquad   \Sigma_t = (I-K_tC_t)\hat{\Sigma}_t$

    return  $\mu_t$ ,$\Sigma_t$ 

### [无迹卡尔曼滤波](https://blog.csdn.net/gangdanerya/article/details/105215446?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link&utm_relevant_index=2)
[](https://blog.csdn.net/qq_37207042/article/details/104062778)

- 无迹卡尔曼滤波数学模型建立
    通过将**非线性控制系统**状态方程转换为**对数据均值点按规则进行采样**,并称为$\sigma$点，该方法可匹配**二阶泰勒展开**结果，该算法避开了对非线性函数进行求导的问题。
    针对上一状态的置信度$bel(x_{t-1})$的均值$\mu_{t-1}$进行采样，采样方式，如下。
    采样2n+1个点，其规则如下：
    $$
    X^{[0]}=\mu_{t-1} \\
    X^{[i]}=\mu_{t-1} +(\sqrt{(n+\lambda)\Sigma})_i  \qquad \qquad i=1,2,...,n \\
    X^{[i]}=\mu_{t-1}-(\sqrt{(n+\lambda)\Sigma})_i  \qquad \qquad i=n+1,n+2,...,2n
    $$
    式中，$\lambda=\alpha^2(n+k)-n$,其中$alpha$和$k$为确定$\sigma$点分布在均值多远的范围内的比例参数。每个$\sigma$点$X^{[i]}$有两个与之相关的权值。一个权值$w_m^{[i]}$,计算均值时使用，另一个权值$w_e^{[i]}$,计算高斯的协方差时使用。
    $$
    w_m^{[0]}=\frac{\lambda}{n+\lambda} \\
    w_e^{[0]}=\frac{\lambda}{n+\lambda}+(1-\alpha^2+\beta) \\
    w_m^{[i]}=w_e^{[i]}=\frac{1}{2(n+\lambda)}
    $$
    选择参数$\beta$对高斯表示的附加的（较高阶）分布信息进行编码。如果分布是精
    确的高斯分布，则 $\beta =2$ 是最佳选择。
    $\sigma$点经过函数g变换，来探测g如何改变了高斯分布的形状。
    $$
    Y^{[i]}=g(X^{[i]})
    $$
    结果高斯分布的参数$(\mu' .\Sigma')$由映射的$\sigma$点$Y^{[i]}$获得，根据如下：
    $$
    \mu^{'}=\sum_{i=0}^{2n}w_m^{[i]}Y^{[i]} \\
    \Sigma^{'}=w_e^{[i]}(\hat\chi_{t}^*-\mu^{'})(\hat\chi_{t}^*-\mu^{'})^T
    $$

- 无迹卡尔曼滤波算法
    ukf($\mu_{t-1}$,$\Sigma_{t-1}$,$u_t$,$z_t$):
    
    $1 \qquad \chi_{t-1}=(\mu_{t-1} \qquad  \mu_{t-1}+\gamma\sqrt{\Sigma_{t-1}} \qquad  \mu_{t-1}-\gamma\sqrt{\Sigma_{t-1}})$
    $2 \qquad \hat\chi_{t}^*=g(u_t,\chi_{t-1})$
    $3 \qquad \hat\mu_{t} =\sum_{i=0}^{2n}w_m^{[i]}\hat\chi_{t}^*$
    $4 \qquad \hat\Sigma_{t}=\sum_{i=0}^{2n}w_c^{[i]}(\hat\chi_{t}^{*[i]}-\hat\mu_{t})(\hat\chi_{t}^{*[i]}-\hat\mu_{t})^T+R_t$
    $5 \qquad \hat\chi_{t}=(\hat\mu_{t} \qquad  \hat\mu_{t}+\gamma\sqrt{\hat\Sigma_{t}} \qquad  \hat\mu_{t}-\gamma\sqrt{\hat\Sigma_{t}})$
    $6 \qquad \hat Z_{t}=h(\hat\chi_{t})$
    $7 \qquad \hat z_{t}=\sum_{i=0}^{2n}w_m^{[i]}\hat Z_{t}^{[i]}$
    $8 \qquad S_{t}=\sum_{i=0}^{2n}w_c^{[i]}(\hat Z_{t}^{[i]}-\hat z_{t})(\hat Z_{t}^{[i]}-\hat z_{t})^T+Q_t$
    $9 \qquad \hat \Sigma_{t}^{x,z}=\sum_{i=0}^{2n}w_c^{[i]}(\hat\chi_{t}^{[i]}-\hat z_{t})(\hat Z_{t}^{[i]}-\hat z_{t})^T$    
    $10 \qquad K_{t}=\hat \Sigma_{t}^{x,z}S_{t}^{-1}$ 
    $11 \qquad \mu_t = \hat{\mu}_t + K_t(z_t-\hat z_t)$
    $12 \qquad \Sigma_t=\hat{\Sigma}_t-K_tS_tK_t^T$
    return  $\mu_t$ ,$\Sigma_t$ 



### 信息滤波

信息滤波(IF)是卡尔曼滤波的对偶滤波算法，二者的不同在于对高斯分布的表示方式。信息滤波以正则参数来表示高斯分布，由一个信息矩阵$\Omega$和信息向量$\xi$组成。
其参数规定如下：
$$
\Omega=\Sigma^{-1} \\
\xi = \Sigma^{-1}\mu 
$$
因此有：
$$
\Sigma=\Omega^{-1} \\
\mu = \Omega^{-1}\xi
$$
对于开始提到的多变量正太分布有：
$$
p(x)=det(2\pi\Sigma)^{-\frac{1}{2}}\exp \left\{ -\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)\right\} \\
=det(2\pi\Sigma)^{-\frac{1}{2}}\exp \left\{ -\frac{1}{2}x^T\Sigma^{-1}x+x^T\Sigma^{-1}\mu-\frac{1}{2}\mu^T\Sigma^{-1}\mu 
\right\} \\
=\eta det(2\pi\Sigma)^{-\frac{1}{2}}\exp \left\{ -\frac{1}{2}x^T\Sigma^{-1}x+x^T\Sigma^{-1}\mu 
\right\} \\
=\eta det(2\pi\Sigma)^{-\frac{1}{2}}\exp \left\{ -\frac{1}{2}x^T\Omega x+x^T\xi 
\right\}
$$

由卡尔曼滤波理论：
$$
x_t = A_tx_t+B_tu_t-\epsilon_t \\
z_t = C_tx_t+\delta_t
$$

而卡尔曼滤波算法为：

kf($\mu_{t-1}$,$\Sigma_{t-1}$,$u_t$,$z_t$):

$1 \qquad    \hat{\mu}_t=A_t\mu_{t-1}+B_tu_t$
$2 \qquad    \hat{\Sigma}_t = A_t\Sigma_{t-1}A_t^T+R_t$
$3 \qquad    K_t = \hat{\Sigma}_tC_t^T(C_t\hat{\Sigma}_tC_t^T+Q_t)^{-1}$
$4 \qquad    \mu_t = \hat{\mu}_t + K_t(z_t-C_t\hat{\mu}_t)$
$5 \qquad    \Sigma_t = (I-K_tC_t)\hat{\Sigma}_t$

return  $\mu_t$ ,$\Sigma_t$ 

因此，有一下变换：
$$
\hat{\Sigma}_t = A_t\Sigma_{t-1}A_t^T+R_t \\
\hat{\Omega}_t=\hat{\Sigma}_t^{-1}=(A_t\Omega_{t-1}^{-1}A_t^T+R_t)^{-1}
$$

$$
\hat{\mu}_t=A_t\mu_{t-1}+B_tu_t \\
\hat{\xi}_t=\Sigma_t^{-1}\hat{\mu}_t=\hat{\Omega}_t\hat{\mu}_t=\hat{\Omega}_t(A_t\mu_{t-1}+B_tu_t)=\hat{\Omega}_t(A_t\Omega_{t-1}^{-1}\xi_{t-1}+B_tu_t) \\
$$


测量更新的置信度为：
$$
bel(x_t)=\eta p(z_t|x_t)\hat {bel}(x_t) \\
= \eta \exp\{-\frac{1}{2}(z_t-C_tx_{t})^TQ_t^{-1}(z_t-C_tx_{t})-\frac{1}{2}(x_t-\hat{\mu}_t)^T\hat{\Sigma}_t^{-1}(x_t-\hat{\mu}_t)\}  \\
=\eta \exp\{-\frac{1}{2}x_t^T[C_t^TQ_t^{-1}C_t+\hat{\Omega}]x_t+x_t^T[C_t^TQ_t^{-1}z_t+\hat{\xi}]\}
$$

因此，测量更新参数为：
$$
\Omega_t=C_t^TQ_t^{-1}C_t+\hat{\Omega}  \\
\xi_t=C_t^TQ_t^{-1}z_t+\hat{\xi}
$$



因此信息滤波算法为：

IF($\xi_{t-1}$,$\Omega_{t-1}$,$u_t$,$z_t$):

$1 \qquad    \hat{\Omega}_t=(A_t\Omega_{t-1}^{-1}A_t^T+R_t)^{-1}$
$2 \qquad   \hat{\xi}_t = \hat{\Omega}_t(A_t\Omega_{t-1}^{-1}\xi_{t-1}+B_tu_t)$
$3 \qquad    \Omega_t=C_t^TQ_t^{-1}C_t+\hat{\Omega}$
$4 \qquad    \xi_t=C_t^TQ_t^{-1}z_t+\hat{\xi}_t$

return  $\xi_{t}$,$\Omega_{t}$

> 信息滤波可以避免当方差为0,其逆无穷大的问题，

### 扩展信息滤波

扩展信息滤波是扩展卡尔曼滤波的对偶。
其算法为：
KIF($\xi_{t-1}$,$\Omega_{t-1}$,$u_t$,$z_t$):
$1 \qquad    \mu_{t-1}=\Omega_{t-1}^{-1}\xi_{t-1}$
$2 \qquad    \hat{\Omega}_t=(G_t\Omega_{t-1}^{-1}G_t^T+R_t)^{-1}$
$3 \qquad   \hat{\xi}_t = \hat{\Omega}_tg(u_t,\mu_{t-1})$
$4 \qquad   \hat{\mu}_t = g(u_t,\mu_{t-1})$
$3 \qquad    \Omega_t=H_t^TQ_t^{-1}H_t+\hat{\Omega}$
$4 \qquad    \xi_t=H_t^TQ_t^{-1}[z_t-h(\hat{\mu}_t)+H_t\hat{\mu}_t]+\hat{\xi}_t$

return  $\xi_{t}$,$\Omega_{t}$

###  小结
> 1. 高斯分布可以以两种不同的方式表示**矩参数**和**正则参数**。矩参数(moments parameterization) 山高斯的**均值(一阶矩)** 和 **(协)方差(二阶矩)** 组成。正则参数由**信息矩阵**和**信息向量**组成。两种参数彼此之间都是对偶的。通过矩阵求逆，可以由一个参数得到另一个参数。
> 2. 贝叶斯滤波可以通过两种参数实现。当使用矩参数时，即是卡尔曼滤波。卡尔曼滤波的对偶就是信息滤波，它用正则参数表示后验。基于控制的卡尔曼滤波的更新计算是简单的，但实现测量则变得困难很多。信息滤波则相反，实现测量是简单的，但是基于控制的滤波更新是有难度的。
> 3. 对千计算正确后验的两种滤波，要满足三种假设：第一，初始置信度必须是高斯分布的。第二，状态转移概率必须包含一个附加独立高斯噪声的与参数呈线性关系的函数。第三，同样也适用于测量概率。它也必须是与参数呈线性关系且附加了高斯噪声的。满足这些假设的系统叫作线性高斯系统。**满足这三个假设就可以使用卡尔曼滤波和信息滤波去计算。**
> 4. 两种滤波方法都能扩展应用于非线性系统。本章描述的一个技术是计算非线性函数的切线。由于切线是线性的，从而使滤波能够适用。寻找切线的技术叫作泰勒级数展开。执行泰勒级数展开涉及计算目标函数的一阶导数，并对其在特定点进行评估。这个操作的结果就是已知雅可比矩阵。这样的滤波就叫“扩展的＂。
> 5. 无迹卡尔曼滤波利用了不同的线性化技术，叫作无迹变换。它将函数在选定点进行线性化，并计算基千这些点的结果的线性近似。该滤波能在不需要雅可比矩阵的情况下实现，即常提到的*无需求导*。用于线性系统时，无迹卡尔曼滤波与卡尔曼滤波是等效的，但无迹卡尔曼滤波经常会为非线性系统提供更好的估计。这种滤波的计算复杂性和扩展卡尔曼滤波是相同的。
> 6. 泰勒级数展开和无迹变换的精确性取决于两个因素一系统的非线性程度和后验的宽度。如果能相对高准确性地知道系统状态，扩展滤波往往会得到好的结果，因此剩余的（协）方差很小。不确定性越大，由线性化引起的误差越高。
> 7. 高斯滤波算法的主要优点之一体现在计算上，即更新需要的时间是状态空间维数的多项式。不过本书第4 章所描述技术并非如此。高斯算法的主要缺点是高斯分布方面的局限。
> 8. 在多元高斯架构里，卡尔曼滤波和信息滤波具有互不相关的优点和缺点。但是，卡尔曼滤波及其非线性扩展的扩展卡尔曼滤波远比信息滤波更流行。
 [color=red]




## 第四章

### 直方图滤波
#### 1 直方图滤波(Histogram Filter)的算法思想

直方图滤波的算法思想在于：它把整个状态空间$dom(x(t))$切分为互不相交的部分$b_1、b_2、b_3、...、b_{n-1}$ ，使得：
$$
\cup_ib_i = dom(x(t)) \tag {4-1}
$$
然后定义一个新的状态空间 $y_t \in \{0,...,n-1 \}$，当且仅当$x(t)\in b_i$ 时，$y_t=i$ ,由于 $y_t$是一个离散的状态空间，我们就可以采用离散贝叶斯算法计算$bel(y_t)$。$bel(y_t)$是对$bel(x_t)$的近似，它给出$x(t)$在每一个 $b_i$的概率， $b_i$划分的越精细，计算的结果就越精确，当然精确的代价是计算成本的上升。

#### 2 1D直方图滤波在自动驾驶定位的应用

如下图所示，无人驾驶汽车在一维的宽度为5m的世界重复循环，因为世界是循环的，所以如果无人驾驶汽车到了最右侧，再往前走一步，它就又回到了最左侧的位置。

![](https://minio.likelihood-tech.com/hackmd/yubo/概率机器人学/4-1-0.jpg) 


自动驾驶汽车上安装有Sensor可以检测车辆当前所在位置的颜色，但Sensor本身的存在一定检测错误率，即Sensor对颜色的检测不是100%准确的；

无人驾驶汽车以自认为1m/step的恒定速度向右运动，**车辆运动本身也存在误差**，即向车辆发出的**控制命令**是**向右移动2m**，而实际的车辆运动结果可能是待在**原地不动**，可能**向右移动1m**，也可能**向右移动3m**。

##### 2.1 **数学模型**

从数学的语言来描述这个问题：机器人只有一个状态变量：位置，$pos(t)\in [0,5)$  。应用直方图滤波(Histogram Filter)，对状态空间做如下分解:
$$
b_0 \in [0,1),b_1 \in [1,2),b_2 \in [2,3),b_3 \in [3,4),b_0 \in [4,5) \tag{4-2}
$$
![](https://minio.likelihood-tech.com/hackmd/yubo/概率机器人学/4-1-1.jpg) 

于是得到一个新的状态空间 $y(t)\in 0,...,4$，**它是对连续状态空间的近似，在某一时刻车辆只能在这些离散状态中的一个**。

虽然车辆自认为在**向右运动，每一步运动1m，我们假设存在5%的概率，无人驾驶汽车仍待在原地没动；存在90%的概率车辆在向右移动1m；存在5%的概率无人驾驶汽车在向右运动2m**。（mod为求余）
$$
P(y_t=(x+2)mod5|y_{t-1}=x)=0.05 \\
P(y_t=(x+1)mod5|y_{t-1}=x)=0.9 \\
P(y_t=x|y_{t-1}=x)=0.05 \tag{4-3}
$$
无人驾驶汽车的Sensor假设**90%的概率感知结果是正确的，还有10%的情况下它感知的结果是错误的**。
$$
P(MeasuredColor_t=Blue|y_t=0,2,3)=0.9 \\
P(MeasuredColor_t=Orange|y_t=0,2,3)=0.1 \\
P(MeasuredColor_t=Blue|y_t=1,4)=0.1 \\
P(MeasuredColor_t=Orange|y_t=1,4)=0.9  \tag{4-4}
$$

##### 2.2 利用直方图滤波(Histogram Filter)进行车辆定位的过程

我们用一个5维的向量来描述t时刻，无人驾驶汽车位于第1个格子、第2个格子、第3个格子、第4个格子、第5个格子的概率。
$$
bel(y_t)=(bel_{t,1},bel_{t,2},bel_{t,3},bel_{t,4},bel_{t,5}) \tag{4-5}
$$
无人驾驶汽车对自己所在位置一无所知，假设它**连续三次【运动-向右走一步】**-【观测】,三次观测结果分别是**orange、blue、orange**，我们一步步无人驾驶汽车是如何通过【运动】-【观测】过程逐步确认自己的位置的。


> **t=0时刻**
>
> 没有任何先验知识，无人车不知道自己在哪里,所以在各个位置概率相等：**(初始置信度)**
> $$
> bel(y_0)=(0.2,0.2,0.2,0.2,0.2) \tag{4-6}
> $$
>
> ```python
> import numpy  as np 
> # 初始置信度
> b = np.array([0.2,0.2,0.2,0.2,0.2])
> ```
>
> **t=1时刻**
>
> 首先向右走1m，用运动模型进行位置预测
> $$
> x=3 \to P(y_t=0|y_{t-1}=3)=0.05 \to P(y_t=4|y_{t-1}=3)=0.9 \to P(y_t=3|y_{t-1}=3)=0.05 \\
> x=4 \to P(y_t=1|y_{t-1}=4)=0.05 \to P(y_t=0|y_{t-1}=4)=0.9 \to P(y_t=4|y_{t-1}=4)=0.05 \\
> x=0 \to P(y_t=2|y_{t-1}=0)=0.05 \to P(y_t=1|y_{t-1}=0)=0.9 \to P(y_t=0|y_{t-1}=0)=0.05 \\
> x=1 \to P(y_t=3|y_{t-1}=1)=0.05 \to P(y_t=2|y_{t-1}=1)=0.9 \to P(y_t=1|y_{t-1}=1)=0.05 \\
> x=2 \to P(y_t=4|y_{t-1}=2)=0.05 \to P(y_t=3|y_{t-1}=2)=0.9 \to P(y_t=2|y_{t-1}=2)=0.05 \\
> $$
>
> ```python
> # 状态转移矩阵
> a = np.array([[0.05,0,0,0.05,0.9],
>            [0.9,0.05,0,0,0.05],  
>            [0.05,0.9,0.05,0,0],
>          [0,0.05,0.9,0.05,0],
>           [0,0,0.05,0.9,0.05]])
> c = np.dot(a,b.T) 
> # 测量结果概率
> d = np.array([0.1,0.9,0.1,0.1,0.9])
> f = c*d/np.sum(c*d)
> ```
>
>
> $$
> \hat {bel}(y_1)=\sum_{y_0}P(p_1|y_0)P(y_0) \\
> =(0.05,0.9,0.05,0,0)*0.2+(0,0.05,0.9,0.05,0)*0.2 \\ 
> +(0,0,0.05,0.9,0.05)*0.2+(0.05,0,0,0.05,0.9)*0.2  \\
> +(0.9,0.05,0,0,0.05)*0.2 \\
> =(0.2,0.2,0.2,0.2,0.2)
> $$
>
> 可以看出无人车虽然向前运动一步，但它仍然对自己所在位置一无所知。这也和我们的认知相同，刚开始完全不知道自己在哪里，走了一步自然也完全不知道自己在哪里。
> 
>
> 再用更新模型通过Sensor感知环境，更新当前位置的置信度。
> $$
> {bel}(y_1)=\eta P(MeasuredColor_t=Orange|y_1)\hat{hat}(y_1) \\
> =\eta(0.1,0.9,0.1,0.1,0.9)*(0.2,0.2,0.2,0.2,0.2) \\
> =\eta(0.02,0.18,0.02,0.02,0.18) \\
> =(0.04762,0.42857,0.04762,0.04762,0.42857)
> $$
> orange的颜色感知信息使得传感器认为自己很可能位于第二个和第五个方格中。
>
> **t=2时刻**
>
> 运动模型-向右走1m
>
> ```python
> c = np.dot(a,f.T)
> d = np.array([0.9,0.1,0.9,0.9,0.1])
> f = c*d/np.sum(c*d)
> ```
>
> 
> $$
> \hat {bel}(y_2)=\sum_{y_1}P(y_2|y_1)P(y_1) \\
> =(0.39047619, 0.08571429, 0.39047619, 0.06666667, 0.06666667)
> $$
>
> 更新模型-sensor环境感知
> $$
> {bel}(y_2)=\eta P(MeasuredColor_2=Blue|y_2)\hat{hat}(y_2) \\
> =(0.45165239, 0.01101591, 0.45165239, 0.07711138, 0.00856793)
> $$
>
>
> **t=3时刻**
>
> 运动模型-向右走1m
>
> ```python
> c = np.dot(a,f)
> d = np.array([0.1,0.9,0.1,0.1,0.9])
> f = c*d/np.sum(c*d)
> ```
> $$
> \hat {bel}(y_3)=\sum_{y_2}P(y_3|y_2)P(y_2) \\
> =(0.03414933, 0.40746634, 0.05507956, 0.41089351, 0.09241126)
> $$
>
> 更新模型-sensor环境感知
> $$
> {bel}(y_3)=\eta P(MeasuredColor_3=Orange|y_3)\hat{bel}(y_3) \\
> =(0.0068312 , 0.73358308, 0.01101807, 0.0821948 , 0.16637285)
> $$
> [color=red]

可以看到经过三次的运动和观测后，无人驾驶汽车已经有73%的概率确认自己位于第二个网格中，事实再经过三次的运动观测，无人驾驶汽车可以有94%的概率确认自己的位置。



### 粒子滤波 

![](https://minio.likelihood-tech.com/hackmd/yubo/概率机器人学/4-2-0.png)
左图显示了3000个基于高斯的正态分布的点。

$$\mu = \begin{bmatrix}0\\0\end{bmatrix},\, \, \, \Sigma = \begin{bmatrix}32&15\\15&40\end{bmatrix}$$

右边的图显示了这些点通过这组方程的情况。

$$\begin{aligned}x&=x+y\\
y &= 0.1x^2 + y^2\end{aligned}$$ 

使用有限数量的随机抽样点来计算一个结果被称为[*蒙特卡洛*](https://en.wikipedia.org/wiki/Monte_Carlo_method)(MC)方法。这个想法很简单。生成足够多的点来获得问题的代表性样本，通过你正在建模的系统运行这些点，然后在转换后的点上计算结果。

简而言之，这就是粒子过滤的作用。我们在书中一直使用的贝叶斯滤波算法被应用于数以千计的粒子，其中每个粒子代表系统的一个*可能的状态*。我们使用粒子的加权统计从成千上万的粒子中提取估计状态。

#### 通用粒子滤波算法
1. **随机生成一堆粒子**。
  粒子可以有位置、方向（和/或）任何其他你需要估计的状态变量。每个粒子都有一个权重（概率），表明它与系统的实际状态相匹配的可能性。用相同的权重初始化每个粒子。
2. **预测粒子的下一个状态**。
 根据你预测真实系统的行为方式来移动粒子。
3. **更新**
  根据测量结果更新粒子的权重。与测量结果密切相关的粒子的权重高于与测量结果不甚相符的粒子。
4. **粒子重采样**
  丢弃极不可能的粒子，用更有可能的粒子的副本取代它们。
5. **计算估计值**
  可以选择计算粒子集的加权平均值和协方差，以获得状态估计。
 
为了进一步理解算法以下面实例进行讲解：

假设在一个二维空间中存在一个物体，其状态值为$（x,y,\theta）$,前两个表示粒子位置，后者表示粒子移动方向。

其运动方程为：

$$
\theta_t = \theta_{t-1}+\delta \\
x_t = x_{t-1}+\cos(\theta_t)(ut+\mu)  \\
y_t = y_{t-1}+\sin(\theta_t)(ut+\mu)
$$

- 随机生成一堆粒子
```python
from numpy.random import uniform
# 均值分布
def create_uniform_particles(x_range, y_range, hdg_range, N):
    """ 
    * @brief create_uniform_particles       -- 创建一堆均匀分布的粒子
    * @param x_range     -- input 粒子在x方向的空间大小
    * @param y_range     -- input 粒子在y方向的空间大小
    * @param hdg_range   -- input 粒子的运动方向
    * @param N           -- input 粒子总数
    * @return particles  -- output 粒子的状态空间
    """
    particles = np.empty((N, 3))
    particles[:, 0] = uniform(x_range[0], x_range[1], size=N)
    particles[:, 1] = uniform(y_range[0], y_range[1], size=N)
    particles[:, 2] = uniform(hdg_range[0], hdg_range[1], size=N)
    particles[:, 2] %= 2 * np.pi
    return particles
# 高斯分布
def create_gaussian_particles(mean, std, N):
    """ 
    * @brief create_gaussian_particles       -- 创建一堆高斯分布的粒子
    * @param mean                            -- input 粒子的状态空间的均值
    * @param std                             -- input 粒子的状态空间的方差
    * @param N                               -- input 粒子总数
    * @return particles                      -- output 粒子的状态空间
    """
    particles = np.empty((N, 3))
    # 为啥是这个公式是由于，产生的随机数必然以均值为中心，以方差半径的圆内落点。
    particles[:, 0] = mean[0] + (randn(N) * std[0])
    particles[:, 1] = mean[1] + (randn(N) * std[1])
    particles[:, 2] = mean[2] + (randn(N) * std[2])
    particles[:, 2] %= 2 * np.pi
    return particles
```
- 预测粒子的下一个状态
```python
def predict(particles, u, std, dt=1.):
    """ 
    * @brief predict       -- 预测粒子的下一个状态
    * @param particles     -- input 粒子的状态变量
    * @param u             -- input 控制变量
    * @param std           -- input 控制系统的方差
    * @param dt            -- input 表示时间变化
    * @return              -- output 
    
    """

    N = len(particles)
    # 更新粒子偏向方向
    particles[:, 2] += u[0] + (randn(N) * std[0])
    particles[:, 2] %= 2 * np.pi

    # 根据偏向方向，计算移动距离。
    dist = (u[1] * dt) + (randn(N) * std[1])
    particles[:, 0] += np.cos(particles[:, 2]) * dist
    particles[:, 1] += np.sin(particles[:, 2]) * dist
 
```
- 通过测量数据更新
每个粒子都有一个位置和一个权重，估计它与测量结果的匹配程度。将权重归一，使它们的总和为1，将它们变成一个概率分布。最接近机器人的粒子通常比远离机器人的粒子有更高的权重。
```python
def update(particles, weights, z, R, landmarks):
    """ 
    * @brief update        -- 更新每个对应粒子的权值
    * @param particles     -- input 粒子的状态变量
    * @param weights       -- input 粒子对应的权值
    * @param z             -- input 测量数据，表示传感器测量到地标的距离
    * @param R             -- input 传感器误差
    * @param landmarks     -- input 地标位置
    * @return              -- output 
    """
    
    for i, landmark in enumerate(landmarks):
        distance = np.linalg.norm(particles[:, 0:2] - landmark, axis=1)
        weights *= scipy.stats.norm(distance, R).pdf(z[i])

    weights += 1.e-300      # 避免分母为0
    weights /= sum(weights) # 归一化
    
```
- 粒子重采样
在对粒子重采样时，需要判断是否需要进行重采样，使用有效N来确定何时重新采样，它近似测量对概率分布有意义的粒子数量。 这个方程是
$$\hat{N}_\text{eff} = \frac{1}{\sum w^2}$$
```python
def neff(weights):
    return 1. / np.sum(np.square(weights))
```

```python
def simple_resample(particles, weights):
    """ 
    * @brief simple_resample  -- 简单重采样
    * @param particles        -- input 粒子的状态变量
    * @param weights          -- input 粒子对应的权值
    * @return                 -- output 
    """
    N = len(particles)
    cumulative_sum = np.cumsum(weights)
    cumulative_sum[-1] = 1. # 避免四舍五入错误
    indexes = np.searchsorted(cumulative_sum, random(N))
    # 根据指数重新取样
    particles[:] = particles[indexes]
    weights.fill(1.0 / N)
```

- 计算估计值
```python
def estimate(particles, weights):
    """ 
    * @brief estimate         -- 计算状态估计量
    * @param particles        -- input 粒子的状态变量
    * @param weights          -- input 粒子对应的权值
    * @return mean, var       -- output 均值和方差
    """
    pos = particles[:, 0:2]
    mean = np.average(pos, weights=weights, axis=0)
    var  = np.average((pos - mean)**2, weights=weights, axis=0)
    return mean, var
```

- 总体主代码：


```python
from filterpy.monte_carlo import systematic_resample
from numpy.linalg import norm
from numpy.random import randn,random
import scipy.stats

    
def run_pf1(N, iters=15, sensor_std_err=.1, 
            do_plot=True, plot_particles=False,
            xlim=(-2, 25), ylim=(-2, 25),
            initial_x=None):
    """ 
    * @brief run_pf1          -- 粒子滤波
    * @param N                -- input 产生粒子的数量
    * @param iters            -- input 迭代次数（机器移动次数）
    * @param sensor_std_err   -- input 传感器的方差
    * @param do_plot          -- input 是否画图
    * @param plot_particles   -- input 是否画粒子的位置
    * @param xlim             -- input x方向画幅范围
    * @param ylim             -- input y方向画幅范围
    * @param initial_x        -- input 初始估计值，可以不用，
    * @return mean, var       -- output 均值和方差
    """
    landmarks = np.array([[-1, 2], [5, 10], [12,14], [18,21]])
    NL = len(landmarks)
    plt.figure()
    # 创建粒子和权重
    if initial_x is not None:
        particles = create_gaussian_particles(
            mean=initial_x, std=(5, 5, np.pi/4), N=N)
    else:
        particles = create_uniform_particles((0,20), (0,20), (0, 6.28), N)
    # 初始化每个粒子的概率 
    weights = np.ones(N) / N
    # 画出粒子的位置图
    if plot_particles:
        alpha = .20
        if N > 5000:
            alpha *= np.sqrt(5000)/np.sqrt(N)           
        plt.scatter(particles[:, 0], particles[:, 1], 
                    alpha=alpha, color='g')
    xs = []
    # 机器人位置 
    robot_pos = np.array([0., 0.])
    for x in range(iters):
        # 机器人位置
        robot_pos += (1, 1)
        # 从机器人到每个地标的距离
        zs = (norm(landmarks - robot_pos, axis=1) + 
              (randn(NL) * sensor_std_err))
        # 斜向移动到（x+1，x+1）。u[0]控制方向 ，u[1]控制移动距离
        particles = predict(particles, u=(0.00, 1.414), std=(.2, .05))
        # 加入测量
        weights = update(particles, weights, z=zs, R=sensor_std_err, 
               landmarks=landmarks)
        # 如果有效颗粒太少就重新取样
        if neff(weights) < N/2:
            simple_resample(particles, weights)
#             indexes = systematic_resample(weights)
#             resample_from_index(particles, weights, indexes)
        mu, var = estimate(particles, weights)
        xs.append(mu)
        if plot_particles:
            plt.scatter(particles[:, 0], particles[:, 1], 
                        color='k', marker=',', s=1)
        p1 = plt.scatter(robot_pos[0], robot_pos[1], marker='+',
                         color='k', s=180, lw=3)
        p2 = plt.scatter(mu[0], mu[1], marker='s', color='r')
        p0 = plt.scatter(landmarks[:, 0], landmarks[:, 1], 
                marker='o', color='b')
        
    xs = np.array(xs)
    #plt.plot(xs[:, 0], xs[:, 1])
    plt.legend([p0,p1, p2], ["landmarks",'Actual', 'PF'], loc=4, numpoints=1)
    plt.xlim(*xlim)
    plt.ylim(*ylim)
    print('final position error, variance:\n\t', mu - np.array([iters, iters]), var)
    plt.show()


run_pf1(N=5000, plot_particles=True)
```

![](https://minio.likelihood-tech.com/hackmd/yubo/概率机器人学/4-2-1.png) 


#### 重采样算法
重采样算法会影响滤波器的性能。例如，假设通过随机选取粒子来进行重采样。这将导致选择许多权重很低的粒子，从而产生的粒子集将存在部分粒子与目标粒子相差较远，从而大大影响优化方向。（粒子缺乏问题）



### 小结：
1 直方图滤波将状态空间分解为有限多个凸区域。该方法用一个单一的数值来表示每个区域的累积后验概率。
2 粒子滤波用从后验提取的状态的随机样本来表示后验。这样的样本叫作粒子群。粒子滤波极容易实现，也是本书中最通用的贝叶斯滤波算法。它不用考虑系统误差是服从何种分布，
3 粒子滤波相比扩展卡尔曼滤波和无迹卡尔曼滤波，其计算量要大很多。

## 总结

粒子滤波基于马尔可夫**蒙特卡洛**方法，通过**抽样**来滤波。
卡尔曼滤波假设**噪声服从高斯分布**，基于**最小方差估计**准则，主要解决线性系统和高斯概率模型的假设。
与粒子滤波的本质区别有两个，第一个，准则不同，卡尔曼滤波本质上是以最小均方差为准则，而粒子滤波本质上是以最大后验概率为准则，第二个重要区别是：粒子滤波不对系统做线性假设和后验概率的高斯假设，是一种非线性、非高斯滤波。
卡尔曼也好，粒子滤波之所以称之为滤波就是因为他们使用初始时刻 x(1) 到当前时刻 x(k)所有的数据估计当前时刻的值。这一类方法都可以称之为滤波。
粒子滤波(PF: Particle Filter)的思想基于蒙特卡洛方法(Monte Carlo methods)，它是利用粒子集来表示概率，可以用在任何形式的状态空间模型上。其核心思想是通过从后验概率中抽取的随机状态粒子来表达其分布，是一种顺序重要性采样法(Sequential Importance Sampling)。简单来说，粒子滤波法是指通过寻找一组在状态空间传播的随机样本对概率密度函数 进行近似，以样本均值代替积分运算，从而获得状态最小方差分布的过程。这里的样本即指粒子,当样本数量N→∝时可以逼近任何形式的概率密度分布。


| 滤波器       | 状态空间 | 先验概率 | 复杂度   | 对外界感知    |
| ------------ | -------- | -------- | -------- | ------------- |
| 直方滤波     | 离散     | 多峰预测 | 指数增长 | 近似（离散）  |
| 卡尔曼滤波器 | 连续     | 单峰预测 | 平方增长 | 近似 （线性） |
| 粒子滤波     | 连续     | 多峰预测 | 复杂     | 近似          |


## 第六章 [机器人感知]^[https://zhuanlan.zhihu.com/p/266909754] ^[https://www.zhihu.com/column/c_1316790747316944896] ^[https://zhuanlan.zhihu.com/p/21879928] ^[slam十四讲]


在构建机器人测量以前，需要指定相应的依托环境地图，一般用M表示。一个地图包含环境中物体的列表及其属性：
$$
M = |m_1,m_2,...,m_N|
$$
式中，N为环境中物体的总数。通常有两种方法,一种是基于位置的，另一种是基于特征的。在基于特征的地图中，n是一个特征的索引。 $m_n$包括特征的属性及特征的笛卡儿位置。在基于位置的地图中，索引号n与特定的位置对应。


### 总结
在利用相机作为传感器时，通过相机随着机器人移动，不断对路标进行拍摄，构建视觉里程计，将这个数据作为测量数据，**然后利用滤波和非线性优化**，从获取运动地图。从而完成机器人定位。








